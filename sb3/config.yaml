num_agents: 5
num_objects: 10
num_sims: 16384
warehouse_width: 200
agent_radius: 1.5
max_speed: 5.0 # how fast we can drive forwards
min_speed: 2.0 # how fast we can drive backwards
max_episode_len: 150
device: cpu
dt: 0.4 # just made this larger to speed up training. Eventually reduce.
steer_actions: [-0.15, 0, 0.15]
accel_actions: [-2, -1, 0, 1, 3]
length: 3.0
width: 1.0
goal_radius: 6.0 # how close we need to get to our goal to have "accomplished" it
num_init_conds: 30000 # how many possible initial conditions we have
reward:
  goal_reward: 1.0
  coll_penalty: 0.1
  reverse_penalty: 0.01

seed: 0
render: false
render_callback: false

runner_configs:
  learning_rate: 0.0003
  n_steps: 128
  batch_size: 16384
  n_epochs: 5
  gamma: 0.999
  gae_lambda: 0.95
  clip_range: 0.2
  clip_range_vf: null
  normalize_advantage: True
  advantage_filter: 0.0 # setting this to too low a value filters out all
                        # the positive advantage so we probably should
                        # do this differently
  ent_coef: 0.0
  vf_coef: 0.5
  max_grad_norm: 0.5
  use_sde: False
  sde_sample_freq: -1
  target_kl: null
  stats_window_size: 100
  tensorboard_log: null
  policy_kwargs: {}
  verbose: 1
  seed: ${seed}
  device: 'cuda'
  _init_setup_model: True
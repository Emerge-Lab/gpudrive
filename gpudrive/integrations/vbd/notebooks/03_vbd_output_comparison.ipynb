{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing VBD Outputs: Waymax vs GPUDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 15:24:52.394752: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742930692.413969   56624 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742930692.419632   56624 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import mediapy\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "# Set working directory to the base directory 'gpudrive'\n",
    "working_dir = Path.cwd()\n",
    "while working_dir.name != 'gpudrive':\n",
    "    working_dir = working_dir.parent.parent\n",
    "    if working_dir == Path.home():\n",
    "        raise FileNotFoundError(\"Base directory 'gpudrive' not found\")\n",
    "os.chdir(working_dir)\n",
    "\n",
    "# GPUDrive dependencies\n",
    "import gpudrive\n",
    "from gpudrive.env.config import EnvConfig, RenderConfig, SceneConfig\n",
    "from gpudrive.env.env_torch import GPUDriveTorchEnv\n",
    "from gpudrive.env.dataset import SceneDataLoader\n",
    "from gpudrive.visualize.utils import img_from_fig\n",
    "\n",
    "# Plotting\n",
    "sns.set(\"notebook\")\n",
    "sns.set_style(\"ticks\", rc={\"figure.facecolor\": \"none\", \"axes.facecolor\": \"none\"})\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/processed' # Base data path\n",
    "CKPT_PATH = 'gpudrive/integrations/vbd/weights/epoch=18.ckpt'\n",
    "\n",
    "SCENARIO_ID = 'efc5cbe01b4a526f'\n",
    "\n",
    "FPS = 20\n",
    "INIT_STEPS = 11 # Warmup period\n",
    "MAX_CONTROLLED_OBJECTS = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Diffusion: 100%|██████████| 50/50 [00:17<00:00,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "#Init GPUDrive env\n",
    "env_config = EnvConfig(\n",
    "    init_steps=INIT_STEPS, # Warmup period\n",
    "    dynamics_model=\"state\", # Use state-based dynamics model\n",
    "    dist_to_goal_threshold=1e-5, # Trick to make sure the agents don't disappear when they reach the goal\n",
    "    init_mode = 'all_non_trivial',\n",
    "    use_vbd=True,\n",
    "    max_controlled_agents=32,\n",
    "    vbd_model_path=CKPT_PATH,\n",
    ")\n",
    "        \n",
    "scene_config = SceneConfig(batch_size=1, dataset_size=1, path=\"data/processed/training\", num_scenes=1)\n",
    "# Make env\n",
    "gpudrive_env = GPUDriveTorchEnv(\n",
    "    config=env_config,\n",
    "    data_loader = SceneDataLoader(\n",
    "        root=\"data/processed/training\",\n",
    "        batch_size=scene_config.batch_size,\n",
    "        dataset_size=scene_config.dataset_size,\n",
    "    ),\n",
    "    render_config=RenderConfig(resolution=(400, 400)),\n",
    "    max_cont_agents=MAX_CONTROLLED_OBJECTS, # Maximum number of agents to control per scene\n",
    "    device=\"cpu\",\n",
    ")\n",
    "gpudrive_sample_batch = gpudrive_env._generate_sample_batch()\n",
    "\n",
    "# Reset predictions tensor\n",
    "pred_trajs = torch.zeros((gpudrive_env.num_worlds, gpudrive_env.max_agent_count, env_config.episode_len-INIT_STEPS, 10))\n",
    "\n",
    "# Fill pred_trajs correctly for each world\n",
    "for i in range(gpudrive_env.num_worlds):\n",
    "    world_agent_indices = gpudrive_sample_batch['agents_id'][i]\n",
    "    \n",
    "    # Filter out negative indices (padding values)\n",
    "    valid_mask = world_agent_indices >= 0  # Boolean mask of valid indices\n",
    "    valid_agent_indices = world_agent_indices[valid_mask]  # Filtered tensor\n",
    "\n",
    "    # Use tensor indexing with valid agent indices\n",
    "    pred_trajs[i, valid_agent_indices, :, :2] = gpudrive_env.vbd_trajectories[i, valid_agent_indices, :, :2]  # pos x, y\n",
    "    pred_trajs[i, valid_agent_indices, :, 3] = gpudrive_env.vbd_trajectories[i, valid_agent_indices, :, 2]    # yaw\n",
    "    pred_trajs[i, valid_agent_indices, :, 4:6] = gpudrive_env.vbd_trajectories[i, valid_agent_indices, :, 3:5]  # vel x, y\n",
    "\n",
    "# Now step through the simulation\n",
    "gpudrive_frames = []\n",
    "for t in range(env_config.episode_len-INIT_STEPS):\n",
    "    gpudrive_env.step_dynamics(pred_trajs[:, :, t, :])\n",
    "    fig = gpudrive_env.vis.plot_simulator_state(\n",
    "        time_steps=[t],\n",
    "        env_indices=[0],\n",
    "        zoom_radius=70,\n",
    "    )[0]\n",
    "    gpudrive_frames.append(img_from_fig(fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF saved at gpudrive/integrations/vbd/viz/train.gif\n"
     ]
    }
   ],
   "source": [
    "mediapy.write_video('gpudrive/integrations/vbd/viz/train.gif', gpudrive_frames, fps=FPS, codec=\"gif\")\n",
    "print(\"GIF saved at gpudrive/integrations/vbd/viz/train.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 80, 10]) torch.Size([1, 64, 80, 5])\n"
     ]
    }
   ],
   "source": [
    "print(pred_trajs.shape, gpudrive_env.vbd_trajectories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([32, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
      "       dtype=torch.int32)\n",
      "tensor([32], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "world_agent_indices = gpudrive_sample_batch['agents_id'][0]\n",
    "valid_mask = world_agent_indices >= 0  # Boolean mask of valid indices\n",
    "valid_agent_indices = world_agent_indices[valid_mask]  # Filtered tensor\n",
    "\n",
    "print(world_agent_indices)\n",
    "print(valid_agent_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting VBD trajectory as part of agent obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_ego_frame(trajectory: torch.Tensor, ego_pos: torch.Tensor, ego_yaw: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Transform trajectory from global coordinates to ego-centric frame.\n",
    "    Args:\n",
    "    trajectory: Shape (time_steps, 2) containing x,y coordinates in global frame\n",
    "    ego_pos: Shape (2,) containing ego x,y position\n",
    "    ego_yaw: Shape (1,) containing ego yaw angle in radians\n",
    "    Returns:\n",
    "    transformed_trajectory: Shape (time_steps, 2) in ego-centric frame\n",
    "    \"\"\"\n",
    "    # Step 1: Translate trajectory to be relative to ego position\n",
    "    translated = trajectory - ego_pos\n",
    "    \n",
    "    # Step 2: Rotate trajectory to align with ego orientation\n",
    "    # Create rotation matrix\n",
    "    cos_yaw = torch.cos(ego_yaw)\n",
    "    sin_yaw = torch.sin(ego_yaw)\n",
    "    rotation_matrix = torch.tensor([\n",
    "        [cos_yaw, sin_yaw],\n",
    "        [-sin_yaw, cos_yaw]\n",
    "    ])\n",
    "    \n",
    "    # Apply rotation matrix to the translated trajectory\n",
    "    # We need to transpose rotation_matrix for batch matrix multiplication\n",
    "    transformed_trajectory = torch.matmul(translated, rotation_matrix.T)\n",
    "    \n",
    "    return transformed_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting vbd trajectory as part of observation\n",
    "from gpudrive.datatypes.observation import GlobalEgoState\n",
    "init_state = gpudrive_env.reset()\n",
    "# Get global agent observations\n",
    "global_agent_obs = GlobalEgoState.from_tensor(\n",
    "    abs_self_obs_tensor=gpudrive_env.sim.absolute_self_observation_tensor(),\n",
    "    backend=gpudrive_env.backend,\n",
    "    device=gpudrive_env.device,\n",
    ")\n",
    "\n",
    "for agent_index in valid_agent_indices:\n",
    "    vbd_trajectory = gpudrive_env.vbd_trajectories[0, agent_index, :, :2]\n",
    "    pos_xy = torch.tensor([global_agent_obs.pos_x[0, agent_index], global_agent_obs.pos_y[0, agent_index]])\n",
    "    yaw = torch.tensor(global_agent_obs.rotation_angle[0, agent_index])\n",
    "\n",
    "    transformed_trajectory = transform_to_ego_frame(vbd_trajectory, pos_xy, yaw)\n",
    "\n",
    "    fig = gpudrive_env.vis.plot_agent_observation(\n",
    "        agent_idx=agent_index,\n",
    "        env_idx=0,\n",
    "        trajectory=transformed_trajectory,\n",
    "        figsize = (4, 4)\n",
    "    )\n",
    "    fig.savefig(f'gpudrive/integrations/vbd/viz/{agent_index}_vbd_trajectory.png', facecolor='white', transparent=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpudrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

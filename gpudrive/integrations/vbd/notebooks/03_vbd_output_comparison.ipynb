{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing VBD Outputs: Waymax vs GPUDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 14:47:51.138446: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744742871.227262   10057 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744742871.257112   10057 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744742871.450339   10057 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744742871.450399   10057 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744742871.450403   10057 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744742871.450406   10057 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import mediapy\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "# Set working directory to the base directory 'gpudrive'\n",
    "working_dir = Path.cwd()\n",
    "while working_dir.name != 'gpudrive':\n",
    "    working_dir = working_dir.parent.parent\n",
    "    if working_dir == Path.home():\n",
    "        raise FileNotFoundError(\"Base directory 'gpudrive' not found\")\n",
    "os.chdir(working_dir)\n",
    "\n",
    "# GPUDrive dependencies\n",
    "import gpudrive\n",
    "from gpudrive.env.config import EnvConfig, RenderConfig, SceneConfig\n",
    "from gpudrive.env.env_torch import GPUDriveTorchEnv\n",
    "from gpudrive.env.dataset import SceneDataLoader\n",
    "from gpudrive.visualize.utils import img_from_fig\n",
    "from gpudrive.integrations.vbd.sim_agent.sim_actor import VBDTest\n",
    "\n",
    "# Plotting\n",
    "sns.set(\"notebook\")\n",
    "sns.set_style(\"ticks\", rc={\"figure.facecolor\": \"none\", \"axes.facecolor\": \"none\"})\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/processed' # Base data path\n",
    "CKPT_PATH = 'gpudrive/integrations/vbd/weights/epoch=18.ckpt'\n",
    "\n",
    "SCENARIO_ID = 'efc5cbe01b4a526f'\n",
    "\n",
    "FPS = 20\n",
    "INIT_STEPS = 11 # Warmup period\n",
    "MAX_CONTROLLED_OBJECTS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VBD model\n",
    "def load_vbd_model(model_path, device=\"cpu\"):\n",
    "    \"\"\"Load the VBD model from a checkpoint, forcing CPU usage.\"\"\"\n",
    "    # Force the model to be loaded on CPU\n",
    "    model = VBDTest.load_from_checkpoint(model_path, torch.device(device))\n",
    "    # Make sure model is in eval mode\n",
    "    _ = model.eval()\n",
    "    return model\n",
    "\n",
    "vbd_model = load_vbd_model(CKPT_PATH, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Diffusion: 100%|██████████| 50/50 [00:27<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "#Init GPUDrive env\n",
    "env_config = EnvConfig(\n",
    "    init_steps=INIT_STEPS, # Warmup period\n",
    "    dynamics_model=\"state\", # Use state-based dynamics model\n",
    "    dist_to_goal_threshold=1e-5, # Trick to make sure the agents don't disappear when they reach the goal\n",
    "    init_mode = 'all_non_trivial',\n",
    "    max_controlled_agents=32,\n",
    "    goal_behavior='ignore'\n",
    ")\n",
    "        \n",
    "# Make env\n",
    "gpudrive_env = GPUDriveTorchEnv(\n",
    "    config=env_config,\n",
    "    data_loader = SceneDataLoader(\n",
    "        root=\"data/processed/training\",\n",
    "        batch_size=2,\n",
    "        dataset_size=2,\n",
    "    ),\n",
    "    render_config=RenderConfig(resolution=(400, 400)),\n",
    "    max_cont_agents=MAX_CONTROLLED_OBJECTS, # Maximum number of agents to control per scene\n",
    "    device=\"cpu\",\n",
    ")\n",
    "gpudrive_sample_batch = gpudrive_env._generate_sample_batch()\n",
    "predictions = vbd_model.sample_denoiser(gpudrive_sample_batch)\n",
    "vbd_output = predictions[\"denoised_trajs\"].to(\"cpu\").detach()\n",
    "\n",
    "# Reset predictions tensor\n",
    "pred_trajs = torch.zeros((gpudrive_env.num_worlds, gpudrive_env.max_agent_count, env_config.episode_len-INIT_STEPS, 10))\n",
    "\n",
    "# World means\n",
    "world_means = gpudrive_env.sim.world_means_tensor().to_torch()[:, :2].to(\"cpu\")\n",
    "\n",
    "# Fill pred_trajs correctly for each world\n",
    "for i in range(gpudrive_env.num_worlds):\n",
    "    world_agent_indices = gpudrive_sample_batch['agents_id'][i]\n",
    "    \n",
    "    # Filter out negative indices (padding values)\n",
    "    valid_mask = world_agent_indices >= 0  # Boolean mask of valid indices\n",
    "    valid_agent_indices = world_agent_indices[valid_mask]  # Filtered tensor\n",
    "\n",
    "    # Use tensor indexing with valid agent indices\n",
    "    pred_trajs[i, valid_agent_indices, :, :2] = vbd_output[i, valid_agent_indices, :, :2] - world_means[i].view(1, 1, 2)  # pos x, y\n",
    "    pred_trajs[i, valid_agent_indices, :, 3] = vbd_output[i, valid_agent_indices, :, 2]    # yaw\n",
    "    pred_trajs[i, valid_agent_indices, :, 4:6] = vbd_output[i, valid_agent_indices, :, 3:5]  # vel x, y\n",
    "\n",
    "# Now step through the simulation\n",
    "gpudrive_frames = []\n",
    "for t in range(env_config.episode_len-INIT_STEPS):\n",
    "    gpudrive_env.step_dynamics(pred_trajs[:, :, t, :])\n",
    "    fig = gpudrive_env.vis.plot_simulator_state(\n",
    "        time_steps=[t],\n",
    "        env_indices=[0, 1],\n",
    "        zoom_radius=120,\n",
    "    )[0]\n",
    "    gpudrive_frames.append(img_from_fig(fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF saved at gpudrive/integrations/vbd/viz/train.gif\n"
     ]
    }
   ],
   "source": [
    "mediapy.write_video('gpudrive/integrations/vbd/viz/train.gif', gpudrive_frames, fps=FPS, codec=\"gif\")\n",
    "print(\"GIF saved at gpudrive/integrations/vbd/viz/train.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpudrive_sample_batch['agents_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'tfrecord-00000-of-01000_401.json', 1: 'tfrecord-00002-of-01000_321.json'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpudrive_env.get_env_filenames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 80, 10]) torch.Size([2, 32, 80, 5])\n"
     ]
    }
   ],
   "source": [
    "print(pred_trajs.shape, vbd_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
      "        [ 0,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]],\n",
      "       dtype=torch.int32)\n",
      "tensor([0, 0, 1], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "world_agent_indices = gpudrive_sample_batch['agents_id']\n",
    "valid_mask = world_agent_indices >= 0  # Boolean mask of valid indices\n",
    "valid_agent_indices = world_agent_indices[valid_mask]  # Filtered tensor\n",
    "\n",
    "print(world_agent_indices)\n",
    "print(valid_agent_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting VBD trajectory as part of agent obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_ego_frame(trajectory: torch.Tensor, ego_pos: torch.Tensor, ego_yaw: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Transform trajectory from global coordinates to ego-centric frame.\n",
    "    Args:\n",
    "    trajectory: Shape (time_steps, 2) containing x,y coordinates in global frame\n",
    "    ego_pos: Shape (2,) containing ego x,y position\n",
    "    ego_yaw: Shape (1,) containing ego yaw angle in radians\n",
    "    Returns:\n",
    "    transformed_trajectory: Shape (time_steps, 2) in ego-centric frame\n",
    "    \"\"\"\n",
    "    # Step 1: Translate trajectory to be relative to ego position\n",
    "    translated = trajectory - ego_pos\n",
    "    \n",
    "    # Step 2: Rotate trajectory to align with ego orientation\n",
    "    # Create rotation matrix\n",
    "    cos_yaw = torch.cos(ego_yaw)\n",
    "    sin_yaw = torch.sin(ego_yaw)\n",
    "    rotation_matrix = torch.tensor([\n",
    "        [cos_yaw, sin_yaw],\n",
    "        [-sin_yaw, cos_yaw]\n",
    "    ])\n",
    "    \n",
    "    # Apply rotation matrix to the translated trajectory\n",
    "    # We need to transpose rotation_matrix for batch matrix multiplication\n",
    "    transformed_trajectory = torch.matmul(translated, rotation_matrix.T)\n",
    "    \n",
    "    return transformed_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      5\u001b[39m global_agent_obs = GlobalEgoState.from_tensor(\n\u001b[32m      6\u001b[39m     abs_self_obs_tensor=gpudrive_env.sim.absolute_self_observation_tensor(),\n\u001b[32m      7\u001b[39m     backend=gpudrive_env.backend,\n\u001b[32m      8\u001b[39m     device=gpudrive_env.device,\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent_index \u001b[38;5;129;01min\u001b[39;00m valid_agent_indices:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     vbd_trajectory = \u001b[43mgpudrive_env\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvbd_trajectories\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     13\u001b[39m     pos_xy = torch.tensor([global_agent_obs.pos_x[\u001b[32m0\u001b[39m, agent_index], global_agent_obs.pos_y[\u001b[32m0\u001b[39m, agent_index]])\n\u001b[32m     14\u001b[39m     yaw = torch.tensor(global_agent_obs.rotation_angle[\u001b[32m0\u001b[39m, agent_index])\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# plotting vbd trajectory as part of observation\n",
    "from gpudrive.datatypes.observation import GlobalEgoState\n",
    "init_state = gpudrive_env.reset()\n",
    "# Get global agent observations\n",
    "global_agent_obs = GlobalEgoState.from_tensor(\n",
    "    abs_self_obs_tensor=gpudrive_env.sim.absolute_self_observation_tensor(),\n",
    "    backend=gpudrive_env.backend,\n",
    "    device=gpudrive_env.device,\n",
    ")\n",
    "\n",
    "for agent_index in valid_agent_indices:\n",
    "    vbd_trajectory = gpudrive_env.vbd_trajectories[0, agent_index, :, :2]\n",
    "    pos_xy = torch.tensor([global_agent_obs.pos_x[0, agent_index], global_agent_obs.pos_y[0, agent_index]])\n",
    "    yaw = torch.tensor(global_agent_obs.rotation_angle[0, agent_index])\n",
    "\n",
    "    transformed_trajectory = transform_to_ego_frame(vbd_trajectory, pos_xy, yaw)\n",
    "\n",
    "    fig = gpudrive_env.vis.plot_agent_observation(\n",
    "        agent_idx=agent_index,\n",
    "        env_idx=0,\n",
    "        trajectory=transformed_trajectory,\n",
    "        figsize = (4, 4)\n",
    "    )\n",
    "    fig.savefig(f'gpudrive/integrations/vbd/viz/{agent_index}_vbd_trajectory.png', facecolor='white', transparent=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpudrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

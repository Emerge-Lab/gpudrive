{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the Sim Manager Object\n",
    "\n",
    "This notebook illustrates the how to work with the GPUDrive Sim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the gpudrive library\n",
    "import gpudrive\n",
    "\n",
    "import torch\n",
    "import jax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A basic sim object with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic initialization of the Sim object \n",
    "sim = gpudrive.SimManager(\n",
    "    exec_mode=gpudrive.madrona.ExecMode.CPU, # Specify the execution mode\n",
    "    gpu_id=0, # If using GPU, specify the GPU ID\n",
    "    auto_reset=False, # If True, the simulation will reset after the episode ends\n",
    "    num_worlds=1, # Initializing only one world\n",
    "    json_path='../nocturne_data', # Path to the json file\n",
    "    params = gpudrive.Parameters() # Default params \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sim exports `reset()` and `step()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.reset(0) # Reset the world with index 0\n",
    "sim.step() # Steps through all the worlds in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get any tensor from the sim, we need to call the specific `tensor()` method followed by `to_torch()` or `to_jax()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 6])\n",
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_tensor = sim.self_observation_tensor().to_torch()\n",
    "print(observation_tensor.shape), print(observation_tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or alternatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 6)\n",
      "{CpuDevice(id=0)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_tensor_jax = sim.self_observation_tensor().to_jax()\n",
    "print(observation_tensor_jax.shape), print(observation_tensor_jax.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available tensor exports and methods on the sim object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute_self_observation_tensor\n",
      "action_tensor\n",
      "agent_roadmap_tensor\n",
      "bicycle_model_tensor\n",
      "controlled_state_tensor\n",
      "depth_tensor\n",
      "done_tensor\n",
      "lidar_tensor\n",
      "map_observation_tensor\n",
      "partner_observations_tensor\n",
      "reset\n",
      "reset_tensor\n",
      "reward_tensor\n",
      "rgb_tensor\n",
      "self_observation_tensor\n",
      "shape_tensor\n",
      "step\n",
      "steps_remaining_tensor\n",
      "valid_state_tensor\n"
     ]
    }
   ],
   "source": [
    "for attr in dir(sim):\n",
    "    if not attr.startswith('_'):\n",
    "        print(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of agents and roads in each world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape tensor has a shape of (Num Worlds, 2):  (1, 2)\n",
      "World  0  has  42  VALID agents and  4421  VALID road objects\n"
     ]
    }
   ],
   "source": [
    "shape_tensor = sim.shape_tensor().to_jax()\n",
    "print(\"Shape tensor has a shape of (Num Worlds, 2): \", shape_tensor.shape)\n",
    "\n",
    "# The shape tensor is a 2D tensor with the first dimension being the number of worlds and the second dimension being the shape of the world\n",
    "for i in range(shape_tensor.shape[0]):\n",
    "    print(\"World \", i, \" has \", shape_tensor[i][0], \" VALID agents and \", shape_tensor[i][1], \" VALID road objects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many agents are controlled by Bicycle Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controlled state tensor has a shape of (Num Worlds, Total Num Agents, 1):  torch.Size([1, 50, 1])\n",
      "Controlled state tensor:  tensor([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0], dtype=torch.int32)\n",
      "Agent indices in the World 0 where the agents are controlled:  tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
      "        21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 41])\n"
     ]
    }
   ],
   "source": [
    "controlled_state_tensor = sim.controlled_state_tensor().to_torch()\n",
    "print(\"Controlled state tensor has a shape of (Num Worlds, Total Num Agents, 1): \", controlled_state_tensor.shape)\n",
    "\n",
    "print(\"Controlled state tensor: \", controlled_state_tensor[0].squeeze())\n",
    "print(\"Agent indices in the World 0 where the agents are controlled: \", torch.where(controlled_state_tensor[0])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current actions tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions tensor has a shape of (Num Worlds, Total Num Agents, 2):  torch.Size([1, 50, 3])\n",
      "Current actions for agent 0 in World 0:  tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "actions_tensor = sim.action_tensor().to_torch()\n",
    "print(\"Actions tensor has a shape of (Num Worlds, Total Num Agents, 2): \", actions_tensor.shape)\n",
    "\n",
    "print(\"Current actions for agent 0 in World 0: \", actions_tensor[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set the action for an agent, we simply copy the actions from another tensor or set it directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ones for all agents in all worlds\n",
      "Actions tensor after setting all actions to 1:  tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "actions_tensor = sim.action_tensor().to_torch()\n",
    "\n",
    "print(\"Setting ones for all agents in all worlds\")\n",
    "actions = torch.full(actions_tensor.shape, 1.0)\n",
    "actions_tensor.copy_(actions)\n",
    "\n",
    "print(\"Actions tensor after setting all actions to 1: \", actions_tensor[0][0])\n",
    "\n",
    "# Call the step function to apply the actions\n",
    "sim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the default parameters of the sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "collisionBehaviour  : gpudrive.CollisionBehaviour.AgentStop\n",
      "datasetInitOptions  : gpudrive.DatasetInitOptions.FirstN\n",
      "maxNumControlledVehicles: 10000\n",
      "observationRadius   : 0.0\n",
      "polylineReductionThreshold: 0.0\n",
      "rewardParams        : <gpudrive.RewardParams object at 0x77728ace3cf0>\n",
      "  Reward Parameters:\n",
      "    distanceToExpertThreshold: 0.0\n",
      "    distanceToGoalThreshold: 0.0\n",
      "    rewardType        : gpudrive.RewardType.DistanceBased\n"
     ]
    }
   ],
   "source": [
    "params = gpudrive.Parameters()\n",
    "\n",
    "print(\"Parameters:\")\n",
    "for attr in dir(params):\n",
    "    if not attr.startswith('__'):\n",
    "        value = getattr(params, attr)\n",
    "        print(f\"{attr:20}: {value}\")\n",
    "        if attr == 'rewardParams':\n",
    "            print(\"  Reward Parameters:\")\n",
    "            reward_params = getattr(params, attr)\n",
    "            for attr2 in dir(reward_params):\n",
    "                if not attr2.startswith('__'):\n",
    "                    value2 = getattr(reward_params, attr2)\n",
    "                    print(f\"    {attr2:18}: {value2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set the parameters of the Sim, just fill in the values for each attr of the param object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_params = gpudrive.RewardParams()\n",
    "reward_params.rewardType = gpudrive.RewardType.DistanceBased\n",
    "reward_params.distanceToGoalThreshold = 1.0\n",
    "reward_params.distanceToExpertThreshold = 1.0 \n",
    "\n",
    "# Initialize Parameters\n",
    "params = gpudrive.Parameters()\n",
    "params.polylineReductionThreshold = 1.0\n",
    "params.observationRadius = 100.0\n",
    "params.datasetInitOptions = gpudrive.DatasetInitOptions.RandomN\n",
    "params.collisionBehaviour = gpudrive.CollisionBehaviour.Ignore\n",
    "params.maxNumControlledVehicles = 10\n",
    "params.rewardParams = reward_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The params object can simply be passed to the sim constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic initialization of the Sim object \n",
    "sim = gpudrive.SimManager(\n",
    "    exec_mode=gpudrive.madrona.ExecMode.CPU, # Specify the execution mode\n",
    "    gpu_id=0, # If using GPU, specify the GPU ID\n",
    "    auto_reset=False, # If True, the simulation will reset after the episode ends\n",
    "    num_worlds=1, # Initializing only one world\n",
    "    json_path='../nocturne_data', # Path to the json file\n",
    "    params = params \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running through one episode of the sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_worlds = 1\n",
    "\n",
    "for i in range(num_worlds):\n",
    "    sim.reset(i)\n",
    "\n",
    "actions_shape = sim.action_tensor().to_torch().shape\n",
    "dones = sim.done_tensor().to_torch()\n",
    "while not torch.all(sim.done_tensor().to_torch()):\n",
    "    obs, rews, dones = sim.self_observation_tensor().to_torch(), sim.reward_tensor().to_torch(), sim.done_tensor().to_torch()\n",
    "    actions = torch.rand(actions_shape)\n",
    "    sim.action_tensor().to_torch().copy_(actions)\n",
    "    sim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "madrona",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

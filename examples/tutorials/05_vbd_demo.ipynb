{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Versatile Behavior Diffusion (VBD) with GPUDrive\n",
    "\n",
    "---\n",
    "\n",
    "> [VBD project page](https://sites.google.com/view/versatile-behavior-diffusion?pli=1) | [ArXiv](https://arxiv.org/abs/2404.02524)\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook we demonstrate how you can generate realistic vehicle trajectories with VBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import warnings\n",
    "import mediapy\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set working directory to the base directory 'gpudrive'\n",
    "working_dir = Path.cwd()\n",
    "while working_dir.name != 'gpudrive':\n",
    "    working_dir = working_dir.parent\n",
    "    if working_dir == Path.home():\n",
    "        raise FileNotFoundError(\"Base directory 'gpudrive' not found\")\n",
    "os.chdir(working_dir)\n",
    "\n",
    "from pygpudrive.env.config import EnvConfig, RenderConfig, SceneConfig, SelectionDiscipline\n",
    "from pygpudrive.env.env_torch import GPUDriveTorchEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - We only control valid agents up to a maximum of 32\n",
    "- The initialization steps: 10\n",
    "- We use the `StateDynamics` model\n",
    "    - this model has a 5D action `(x, y, yaw, velocity x, velocity y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_config = SceneConfig(\n",
    "    path=\"data/examples\", \n",
    "    num_scenes=1,\n",
    "    discipline=SelectionDiscipline.K_UNIQUE_N,\n",
    "    k_unique_scenes=1,\n",
    ")\n",
    "\n",
    "env_config = EnvConfig(\n",
    "    init_steps=10, # Warmup period\n",
    "    enable_vbd=True, # Use VBD\n",
    "    dynamics_model=\"state\", # Use state-based dynamics model\n",
    ")\n",
    "\n",
    "render_config = RenderConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ratio unique scenes / number of worls =         1 / 1 ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = GPUDriveTorchEnv(\n",
    "    config=env_config,\n",
    "    scene_config=scene_config,\n",
    "    render_config=render_config,\n",
    "    max_cont_agents=32, # Maximum number of agents to control per scene\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected agents: [0, 1, 5]\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: We have a warmup period of 10 steps, so the first step should be 11\n",
    "env.reset();\n",
    "env.step_in_episode\n",
    "\n",
    "selected_agents = torch.nonzero(env.cont_agent_mask[0, :]).flatten().tolist()\n",
    "\n",
    "print(f\"Selected agents: {selected_agents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained VBD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "from vbd.sim_agent.sim_actor import VBDTest, sample_to_action\n",
    "\n",
    "ckpt_path = 'vbd/weights/epoch=18.ckpt'\n",
    "\n",
    "model = VBDTest.load_from_checkpoint(ckpt_path, map_location=torch.device('cpu'))\n",
    "_ = model.cuda()\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: sample_batch shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agents_history torch.Size([1, 32, 11, 8])\n",
      "agents_interested torch.Size([1, 32])\n",
      "agents_type torch.Size([1, 32])\n",
      "agents_future torch.Size([1, 32, 80, 5])\n",
      "traffic_light_points torch.Size([1, 16, 3])\n",
      "polylines torch.Size([1, 256, 30, 5])\n",
      "polylines_valid torch.Size([1, 256])\n",
      "relations torch.Size([1, 304, 304, 3])\n",
      "agents_id torch.Size([1, 3])\n",
      "anchors torch.Size([1, 32, 64, 2])\n"
     ]
    }
   ],
   "source": [
    "sample = env.warmup_trajectory\n",
    "\n",
    "for key in sample.keys():\n",
    "    print(key, sample[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rollout without goal guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Diffusion: 100%|██████████| 50/50 [00:01<00:00, 36.67it/s]\n"
     ]
    }
   ],
   "source": [
    "replan_freq=80 # Roll out every X steps 80 means openloop\n",
    "model.early_stop=0 # Stop Diffusion Early From 100 to X\n",
    "model.skip = 1 # Skip Alpha \n",
    "model.reward_func = None\n",
    "\n",
    "# Reset the environment\n",
    "init_state = env.reset()\n",
    "\n",
    "current_state = init_state\n",
    "\n",
    "# Obtain all info for diffusion model (warmup)\n",
    "sample_batch = env.warmup_trajectory\n",
    "\n",
    "# Make a prediction\n",
    "pred = model.sample_denoiser(sample_batch)#, x_t=x_t)\n",
    "traj_pred = pred['denoised_trajs'].cpu().numpy()[0]\n",
    "\n",
    "is_controlled = sample_batch['agents_interested'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replan at  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Diffusion:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Diffusion: 100%|██████████| 50/50 [00:01<00:00, 37.10it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid agents_id size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# TODO: Convert sample to action\u001b[39;00m\n\u001b[1;32m     16\u001b[0m action_sample \u001b[38;5;241m=\u001b[39m traj_pred[:, t, :]\n\u001b[0;32m---> 17\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43msample_to_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_controlled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselected_agents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Step the environment with predicted actions\u001b[39;00m\n\u001b[1;32m     20\u001b[0m env\u001b[38;5;241m.\u001b[39mstep_dynamics(action)\n",
      "File \u001b[0;32m~/daphne/gpudrive/vbd/sim_agent/utils.py:209\u001b[0m, in \u001b[0;36msample_to_action\u001b[0;34m(sample, is_controlled, agents_id, max_num_objects)\u001b[0m\n\u001b[1;32m    207\u001b[0m     agents_id_full[is_controlled] \u001b[38;5;241m=\u001b[39m agents_id\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid agents_id size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(agents_id_full):\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid agents_id size"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "\n",
    "for i in range(80):\n",
    "    t = i % replan_freq\n",
    "    if t == 0:\n",
    "        print(\"Replan at \", i)\n",
    "        \n",
    "        # Obtain all info for diffusion model (warmup)\n",
    "        sample_batch = env.warmup_trajectory\n",
    "\n",
    "        # Make a prediction\n",
    "        pred = model.sample_denoiser(sample_batch)#, x_t=x_t)\n",
    "        traj_pred = pred['denoised_trajs'].cpu().numpy()[0]\n",
    "\n",
    "    # TODO: Convert sample to action\n",
    "    action_sample = traj_pred[:, t, :]\n",
    "    action = sample_to_action(action_sample, is_controlled, agents_id=selected_agents)\n",
    "    \n",
    "    # Step the environment with predicted actions\n",
    "    env.step_dynamics(action)\n",
    "    \n",
    "    # TODO: Render the environment\n",
    "    frame = env.render(world_render_idx=0)\n",
    "    frames.append(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo: Show generated trajectories without goal guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a list of frames of shape (H, W, 3) and displays them as a video\n",
    "mediapy.show_video(frames, fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate goal positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
